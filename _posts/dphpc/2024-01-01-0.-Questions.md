---
tags: [Parallel-computing, Multithread, Questions]
title: "DPHPC Exam Questions"
categories: dphpc lecture-notes
---

# Implement `MPI_Barrier(MPI_Comm comm)`

It blocks all processes calling it, until all processes in `comm` have called this function. The efficiency of your implementation is not important for this task, only correctness.

```c
void MPI_Barrier(MPI_Comm comm){
 int buf, rank, size;

 MPI_Comm_rank(comm, &rank);
 MPI_Comm_size(comm, &size);
 math: true
 int tag = 42;
 if (rank == 0){

  for(int rank = 1; rank < size; rank++)
   MPI_Recv(&buf, 1, MPI_INT, i, tag, comm, MPI_STATUS_IGNORE);


  for(int rank = 1; rank < size; rank++)
   MPI_Send(&buf, 1, MPI_INT, i, tag, comm);
 } else {
 buf = 99;
 MPI_Send(&buf, 1, MPI_INT, 0, tag, comm);
 MPI_Recv(&buf, 1, MPI_INT, 0, tag, comm, MPI_STATUS_IGNORE);

 }
}

int main(char* argv[], int argc){
 MPI_init(&argv, &argc);
 MPI_Barrier(MPI_COMM_WORLD)
 MPI_Finalize();
}
```

# Outline in detail a depth optimal algorithm to compute the sum of two $N\times N$  matrices

Depending on the number of processors, divide the matrices into blocks (or submatrices) and assign each block to one processor. Now each processor will perform a matrix addition on the assigned blocks, executing ${\frac n b}^2$ additions.

## What is the work, depth and average parallelism of your algorithm?

The total work will be $W(n) = n^2$, while the depth will be dependant on how many processors we have. If we have $n^2$ processors, the depth would be $1$. This means that$\text{ for } p\rightarrow \infty, D(n)= 1$.
The average parallelism is thus $n^2$.

# A task has a sequential fraction of 40%. What is the best possible speedup for that task using Amdahl's law?

According to Amdahl's law, it's $\frac 1 {0.4} = 2.5$

## How many parallel processing units are required to complete the task 4 times faster than the sequential execution?

It's impossible to achieve. With infinitely many processors, the maximum speedup, according to Amdahl's law, is 2.5.

# What does it mean to say a program is data oblivious? Give a definition

For each problem size, The execution trace, the memory locations read and written do not depend on any input, and are determined by the input size.

# What does it mean to say a program is structurally oblivious? Give a definition

The code does only contain if-statements which depend on the input variables that contain the problem size, and no other input.

# Assume a system with a CPU that has peak performance $\pi$ of 4 single precision FLOPS per cycle, and with a memory bandwidth $\beta$ of 8 bytes per cycle. The last level cache is directly mapped and has size $w$ 2MiB. Draw a roofline plot for this system

Horizontal line at 4 FLOPS/cycle
Intersection at $\pi=\beta I\rightarrow 4 = 8I\rightarrow I = \frac 1 2$
Diagonal line defined by $y= \beta I= 8I$.
![](/assets/img/Pasted%20image%2020240122122237.png)

# What is the advantage of using a work-stealing scheduler instead of a greedy one?

It's more efficient in case work is not evenly distributed among processors. This is because idle workers can steal work from overloaded workers.

# What is the difference between strong- and weak-scaling?

Strong scaling measures the speedup for a fixed problem size as $p\rightarrow \infty$ . Basically, complete the same amount of work faster.

Weak scaling measures the speedup as $p\rightarrow \infty, n\rightarrow \infty$ . In other words, more processors allow us to do more work.

# What does it mean for an algorithm to be balanced with respect to a given architecture?

Compute time = Data transfer time
