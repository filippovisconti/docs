---
tags: [Work-stealing, Parallel-computing, Multithread]
title: "Work-stealing"
categories: dphpc lecture-notes
---

# Little’s law

Given a stable system (i.e., input rate = output rate), the long-term average number of items in the system, $𝑁$, is equal to the average throughput, $\beta$, multiplied by the average time an item spends in the system, $\alpha$. $$N = \alpha ∙ \beta$$ Little’s law tells us how much data is in flight.

## Example: Memory System

![](/assets/img/ScreenShot%202024-01-10%20at%2019.22.05.png)

# Arithmetic intensity

Given a program P, express number of operations per loaded data.

> [!NOTE] Arithmetic intensity $$A(n)=\frac {W(n)} {L(n)}= \frac {\text{num flops}} {\text{num bytes loaded}}$$

Advantage: very simple to calculate!

- Quite useful for basic algorithmic optimizations (but very limited) Disadvantage: does not model the effect of a cache/scratchpad
- A cache would be able to serve many loads at highly reduced cost Operational intensity refines this concept.

# Operational intensity

Given a program P, assume cold (empty) cache

> [!NOTE] Operational intensity $$I(n)=\frac {W(n)} {Q(n)}= \frac {\text{num flops}} {\text{bytes transferred between cache and RAM}}$$

Advantage: very simple to calculate!

- Quite useful for basic algorithmic optimizations (but very limited) Disadvantage: does not model the effect of a cache/scratchpad
- A cache would be able to serve many loads at highly reduced cost Operational intensity refines this concept.

## Asymptotic bounds on 𝑰(𝑛)

> [!Warning] assuming only compulsory misses (infinite cache size for simplicity)

| Operation                                        | $I(n)$      |
| ------------------------------------------------ | ----------- |
| Vector sum: $𝑦 = 𝑥 + 𝑦$                          | $O(1)$      |
| Matrix-vector product: $𝑦 = 𝐴𝑥$                  | $O(1)$      |
| Fast Fourier transform                           | $O(\log n)$ |
| Matrix-matrix product: $𝐶 = 𝐴𝐵 +C$               | $O(n)$      |
| ![](/assets/img/ScreenShot%202024-01-11%20at%2011.50.59.png) |             |

## Balance principles I (Kung 1986)

![](/assets/img/ScreenShot%202024-01-10%20at%2019.44.02.png) ![](/assets/img/ScreenShot%202024-01-11%20at%2011.51.58.png)

## Roofline model

![](/assets/img/ScreenShot%202024-01-11%20at%2011.52.40.png) Different optimizations can be represented as performance ceilings ⇒ you cannot break through a ceiling without performing the associated optimisation. ![](/assets/img/ScreenShot%202024-01-11%20at%2012.06.43.png)

![](/assets/img/ScreenShot%202024-01-10%20at%2019.41.10.png)

Assume CPU performance $𝜋$ increases by a factor of $𝑎$ (i.e., $𝑎𝜋$), how to rebalance? ![](/assets/img/ScreenShot%202024-01-10%20at%2019.43.05.png)

### Algorithm/program model

Work: $𝑊$ \[number of ops\] Data movement: $𝑄_𝑚$ \[byte\] (mem cache)

$$\frac \pi \beta = \frac W {Q_m}=I$$

How much do we need to increase the cache size, $𝛾$, to balance the increase in CPU performance? ![](/assets/img/ScreenShot%202024-01-10%20at%2019.52.16.png)

## Alpha-Beta model

![](/assets/img//assets/img/ScreenShot%202024-01-10%20at%2019.52.48.png)

Time taken to transfer data of size $𝑛$: $T(n) = \frac n \beta+\alpha$ In some literature, $𝛽$ describes inverse bandwidth, and the cost of transferring data grows linearly with $𝑛$.

## Balance Principles II

Objective: More detailed balance principles for multicores, assessment of hardware trends. ![](/assets/img/ScreenShot%202024-01-11%20at%2015.50.33.png) ![](/assets/img/ScreenShot%202024-01-11%20at%2015.50.47.png)

### Derivation

Estimate $T_{mem}$ by dividing DAG into levels. $$Q_{\gamma,\lambda}=\sum^D_{i=1} q_i$$ ![](/assets/img/ScreenShot%202024-01-11%20at%2015.53.10.png)

Then, apply alpha-beta model to each level: $$T_{mem}\approx \sum^D_{i=1}(\frac {q_i \lambda} \beta + \alpha)=\alpha D+ \frac {Q\lambda} \beta$$ Brent's lemma:$$T_{comp} \approx \frac {D+\frac W p} \pi$$

> [!NOTE] Balance Principle
> $T_{mem} \leq T_{comp}$
> $$\frac {p \pi} {\beta} (1+\frac {\alpha \beta / \lambda} {Q/D}) \leq \frac {W} {Q\lambda} (1+\frac p {W/D})$$

![](/assets/img/ScreenShot%202024-01-11%20at%2016.07.39.png)

### Matrix multiplication

![](/assets/img/ScreenShot%202024-01-11%20at%2016.08.22.png)
